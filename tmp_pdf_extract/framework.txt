

===== PAGE 1 =====
 Saint  Louis  University  SCHOOL  OF  ACCOUNTANCY,  MANAGEMENT,  COMPUTING   AND  INFORMATION  STUDIES     Operationalizing  Legal  Literacy:  A  Code-Switched  Adaptive  Routing  Framework  on  Hong  
Kong
 
Labor
 
Laws
 
for
 
the
 
Protection
 
of
 
Filipino
 
Migrant
 
Workers
   __________________________   A  Research  Proposal   Presented  to  the  faculty  of  the   School  of  Computing  and  Information  Sciences   Saint  Louis  University   __________________________   In  Partial  Fulfillment  of  the  Requirements  of  course   Thesis  1   __________________________   By    De  Leon  Earl  Macy  Diola  Josh  McKenzie  Lachica  Rafael  Lucban  Prince  John  Louie  Navarro  Josiah  Ezra  Ramos  Albert  Jannsen  Retuta  Ian  Benedick  Yuen  Ka  Hang  Christian    Rona  E.  Domantay  Faculty  Research  and  Innovation  Promoter      
 


===== PAGE 2 =====
1    Abstract ............................................................................................................................................ 2 CHAPTER  1 .................................................................................................................................... 3 Background  of  the  Study ........................................................................................................... 3 Problem  Statement ..................................................................................................................... 4 Objectives  of  the  Study .............................................................................................................. 5 Project  Scope ............................................................................................................................. 6 Data  Sources .............................................................................................................................. 6 Language  Handling .................................................................................................................... 7 Hypothesis .................................................................................................................................. 7 II.  Research  Framework ................................................................................................................... 8 Conceptual  Framework .................................................................................................................... 8 III.  Significance  of  the  Study ........................................................................................................... 9 CHAPTER  2 .................................................................................................................................. 10 Research  Design  and  Methodology ............................................................................................... 10 Data  Acquisition  and  Preparation ............................................................................................ 10 System  Architecture  Modules .................................................................................................. 10 Document-Based  Comparative  Analysis ................................................................................. 11        Multi-Head  Classifier  for  Code-Switched  Queries ........................................................... 11        Dual-Jurisdiction  Retrieval  Pipeline ................................................................................. 11        Literacy-Adaptive  Safety  Layer ........................................................................................ 11        Quantifying  Computational  and  Hallucination  Performance ........................................... 12        Validate  System  Reliability  through  Expert  Human-in-the-Loop  (HitL)  Assessment ..... 12 Evaluation  Framework  &  Benchmarking ................................................................................ 12        Establishment  of  Groundtruth  for  Evaluation  Metrics ...................................................... 13               Data  Validation  Record .............................................................................................. 13        Benchmarking  (Our  model  vs  Vanilla  LLMs) .................................................................. 14        Evaluation  Criteria  for  the  Experts ................................................................................... 16              Interpretability  Criteria ............................................................................................... 18              Pipeline  -  Adaptive  Framework  Design ...................................................................... 18 Annexes .......................................................................................................................................... 20 A.  Plan  for  dissemination ............................................................................................................... 20 B.  Work  plan  and  schedule  of  activities  (Gantt  chart) ............................................................. 20 C.  Expert-Academic  Partnerships ............................................................................................ 21    

===== PAGE 3 =====
2    Abstract    This  study  advocates  for  ease  of  understanding  labor  laws  for  Overseas  Filipino  Workers  
(OFWs)
 
as
 
they
 
struggle
 
with
 
language
 
barriers,
 
a
 
lack
 
of
 
familiarity
 
with
 
legal
 
terms,
 
and
 
the
 
overall
 
complexity
 
of
 
foreign
 
labor
 
regulations/dual-jurisdiction
 
labor
 
frameworks.
 
Given
 
that
 
Filipinos
 
make
 
up
 
more
 
than
 
half
 
of
 
Hong
 
Kong’s
 
foreign
 
domestic
 
helper
 
population,
 
this
 
difficulty
 
in
 
grasping
 
minimum
 
wage
 
rules,
 
contract
 
terms,
 
and
 
dispute-resolution
 
processes
 
impacted
 
a
 
large
 
and
 
vulnerable
 
group
 
of
 
workers.
 
Previous
 
studies
 
mentioned
 
that
 
“even
 
lawyers
 
don’t
 
like
 
legalese”,
 
emphasizing
 
how
 
legal
 
documents
 
can
 
even
 
be
 
hard
 
to
 
understand
 
for
 
educated
 
individuals
 
due
 
to
 
the
 
nature
 
of
 
law
 
being
 
re.
 
While
 
Large
 
Language
 
Models
 
(LLMs)
 
offer
 
scalable
 
legal
 
assistance,
 
general-purpose
 
models
 
suffer
 
from
 
high
 
hallucination
 
rates
 
and
 
fail
 
to
 
distinguish
 
between
 
conflicting
 
jurisdictional
 
mandates
 
(e.g.,
 
Philippine
 
protectionist
 
policies
 
vs.
 
Host
 
Country
 
statutes).
 
Furthermore,
 
standard
 
models
 
struggle
 
to
 
process
 
code-switched
 
vernacular
 
(Taglish).
 
To
 
address
 
these
 
issues,
 
this
 
research
 
proposes
 
a
 
multilingual
 
and
 
scalable
 
NLP
 
framework.
 
It
 
will
 
integrate
 
advanced
 
technologies
 
such
 
as
 
Retrieval-Augmented
 
Generation
 
(RAG),
 
a
 
Context-Aware
 
Adaptive
 
Model
 
Routing
 
Framework.
 
Drawing
 
on
 
cost-efficient
 
cascading
 
architectures,
 
the
 
system
 
dynamically
 
routes
 
queries
 
based
 
on
 
complexity:
 
procedural
 
inquiries
 
are
 
handled
 
by
 
retrieval-augmented
 
smaller
 
models,
 
while
 
complex
 
cross-border
 
disputes
 
are
 
routed
 
to
 
reasoning-intensive
 
large
 
models.
 
Crucially,
 
the
 
framework
 
integrates
 
a
 
Safety
 
Audit
 
Layer
 
validated
 
against
 
legal
 
meaning
 
preservation
 
metrics
 
to
 
ensure
 
that
 
simplified
 
outputs
 
remain
 
legally
 
accurate.
 
This
 
approach
 
aims
 
to
 
help
 
OFWs
 
better
 
understand
 
their
 
rights
 
and
 
practice
 
their
 
given
 
legal
 
protections.
    

===== PAGE 4 =====
3  CHAPTER  1   
Background  of  the  Study  The  large  number  of  Filipino  domestic  workers  in  Hong  Kong  began  with  a  policy  
introduced
 
by
 
the
 
Philippine
 
government
 
in
 
1974.
 
This
 
policy
 
encouraged
 
educated
 
but
 
unemployed
 
Filipinos
 
to
 
work
 
abroad,
 
earning
 
money
 
and
 
sending
 
remittances
 
home,
 
which
 
supported
 
the
 
country’s
 
economy
 
(Ruiz,
 
2014).
 
Because
 
Hong
 
Kong
 
was
 
easily
 
accessible
 
and
 
offered
 
stable
 
jobs,
 
many
 
Filipinos
 
chose
 
to
 
work
 
there
 
as
 
domestic
 
helpers.
 
Over
 
time,
 
this
 
type
 
of
 
work
 
was
 
common
 
and
 
accepted
 
in
 
both
 
the
 
Philippines
 
and
 
Hong
 
Kong
 
(Mak,
 
2025).
 
Decades
 
later,
 
this
 
migration
 
policy
 
resulted
 
in
 
a
 
massive
 
and
 
continuously
 
growing
 
factor
 
in
 
the
 
region.
  A  thorough  understanding  of  labor  laws  is  crucial  for  Overseas  Filipino  Workers  (OFWs),  
particularly
 
those
 
working
 
in
 
high-risk
 
employment
 
contexts,
 
such
 
as
 
foreign
 
domestic
 
work.
 
Hong
 
Kong
 
remains
 
one
 
of
 
the
 
primary
 
destinations
 
for
 
Filipino
 
migrant
 
labor,
 
with
 
official
 
records
 
showing
 
approximately
 
199,516
 
Filipino
 
domestic
 
workers
 
in
 
2023
 
and
 
in
 
2024,
 
a
 
1.73%
 
increase
 
to
 
202,972
  
(Statistics
 
on
 
the
 
Number
 
of
 
Foreign
 
Domestic
 
Helpers
 
in
 
Hong
 
Kong
 
(Traditional
 
Chinese)
 
|
 
DATA.GOV.HK,
 
2025).
 
  However,  these  statistics  often  mask  the  actual  experiences  faced  by  these  workers.  
According
 
to
 
Yeung
 
(2020),
 
many
 
domestic
 
workers
 
in
 
Hong
 
Kong
 
live
 
and
 
work
 
in
 
the
 
same
 
cramped
 
apartments
 
as
 
their
 
employers
 
due
 
to
 
high
 
housing
 
costs
 
and
 
limited
 
space.
 
This
 
often
 
leads
 
to
 
long
 
hours,
 
no
 
privacy,
 
poor
 
living
 
conditions,
 
and
 
even
 
abuse.
 
Because
 
Hong
 
Kong’s
 
law
 
requires
 
them
 
to
 
live
 
with
 
their
 
employer
 
and
 
ties
 
their
 
visa
 
to
 
a
 
single
 
job,
 
leaving
 
an
 
unsafe
 
situation
 
can
 
mean
 
losing
 
their
 
legal
 
status
 
and
 
income
 
in
 
2019.
 
  These  conditions  violate  their  right  to  decent  work,  a  key  part  of  Sustainable  
Development
 
Goal
 
8
 
which
 
includes
 
safe
 
working
 
environments,
 
fair
 
treatment,
 
and
 
the
 
right
 
to
 
rest.
 
At
 
the
 
same
 
time,
 
the
 
system
 
deepens
 
inequality
 
between
 
local
 
employers
 
and
 
migrant
 
workers,
 
who
 
have
 
fewer
 
rights
 
and
 
less
 
protection
 
than
 
other
 
workers.
 
This
 
goes
 
against
 
SDG
 
10,
 
which
 
calls
 
for
 
reducing
 
inequalities
 
within
 
and
 
among
 
countries,
 
especially
 
for
 
vulnerable
 
groups
 
like
 
migrant
 
domestic
 
workers.
 
This
 
highlights
 
the
 
importance
 
of
 
accessible
 
tools
 
that
 
can
 
help
 
Filipino
 
OFWs
 
better
 
understand
 
their
 
rights
 
and
 
the
 
legal
 
frameworks
 
governing
 
their
 
employment.
 
Despite
 
these
 
challenges,
 
Filipino
 
domestic
 
workers
 
in
 
Hong
 
Kong
 
are
 
not
 
necessarily
 
illiterate
 
or
 
lacking
 
formal
 
education.
 
Earlier
 
research
 
by
 
Battistella
 
and
 
Asis
 
(2011)
 
found
 
that
 
a
 
significant
 
proportion
 
of
 
Filipino
 
domestic
 
workers
 
in
 
Hong
 
Kong
 
possess
 
tertiary
 
education,
 
yet
 
still
 
demonstrate
 
limited
 
knowledge
 
and
 
understanding
 
of
 
government
 
labor
 
regulations.
 
This
 
finding
 
remains
 
relevant
 
nearly
 
a
 
decade
 
later.
 
Sicat
 
(2020)
 
similarly
 
observed
 
that
 
Overseas
 
Filipino
 
Workers
 
in
 
Hong
 
Kong
 
exhibit
 
relatively
 
high
 
educational
 
attainment
 
and
 
are
 
not
 
illiterate,
 
reinforcing
 
the
 
persistence
 
of
 
the
 
education–legal
 
literacy
 
gap
 
identified
 
in
 
earlier
 
studies.
 
Moreover,
 
recent
 
evidence
 
suggests
 
that
 
this
 
gap
 
is
 
compounded
 
by
 
digital
 
behavior
 
patterns.
 
While
 
OFWs
 
in
 
destinations
 
such
 
as
 
the
 
United
 
Arab
 
Emirates
 
have
 
adopted
 
digital
 
self-service
 
tools
 
for
 
remittances
 
at
 
a
 
rate
 
of
 
69.8%,
 
Hong
 
Kong-based
 
OFWs
 
exhibit
 
a
 
distinct
 
digital
 
hesitancy,
 
maintaining
 
a
 
strong
 
preference
 
for
 
face-to-face
 
and
 
manual
 

===== PAGE 5 =====
4  transactions  due  to  trust-related  concerns  (Rojas  &  Narsico,  2025).  This  preference  indicates  
structural
 
and
 
behavioral
 
barriers
 
to
 
digital
 
legal
 
assistance,
 
further
 
limiting
 
access
 
to
 
formal,
 
scalable
 
legal
 
information
 
channels
 
despite
 
the
 
availability
 
of
 
online
 
resources.
  A  critical  factor  perpetuating  this  vulnerability  is  the  lack  of  legal  literacy  among  the  
workforce.
 
A
 
study
 
conducted
 
by
 
the
 
Hong
 
Kong
 
Polytechnic
 
University,
 
which
 
included
 
interviews
 
with
 
over
 
700
 
Filipino
 
and
 
Indonesian
 
domestic
 
workers
 
and
 
surveys
 
with
 
more
 
than
 
400
 
participants,
 
identified
 
that
 
many
 
migrant
 
workers
 
experience
 
difficulty
 
understanding
 
key
 
labor
 
protections,
 
such
 
as
 
minimum
 
allowable
 
wage
 
rules,
 
limitations
 
on
 
working
 
hours,
 
and
 
rest-day
 
policies
 
(Oktavianus,
 
2025).
 
The
 
study
 
further
 
notes
 
that
 
language
 
barriers
 
and
 
unfamiliarity
 
with
 
legal
 
terminology
 
reduce
 
workers’
 
ability
 
to
 
interpret
 
contracts
 
and
 
navigate
 
dispute-resolution
 
processes.
  Currently,  OFWs  face  a  significant  information  gap  when  attempting  to  navigate  these  
legal
 
challenges.
 
The
 
International
 
Labour
 
Organization
 
(2017)
 
reports
 
that
 
despite
 
the
 
existence
 
of
 
labor
 
laws
 
on
 
government
 
portals,
 
significant
 
language
 
barriers
 
pose
 
a
 
problem
 
for
 
migrant
 
workers'
 
understanding
 
of
 
their
 
legal
 
rights.
 
In
 
the
 
absence
 
of
 
accessible
 
interpretation
 
systems,
 
many
 
workers
 
rely
 
on
 
informal
 
digital
 
spaces
 
such
 
as
 
social
 
media
 
to
 
seek
 
advice,
 
a
 
phenomenon
 
Cabalquinto
 
and
 
Soriano
 
(2022)
 
describe
 
as
 
‘digital
 
labor
 
bayanihan.’
 
While
 
these
 
community-driven
 
networks
 
on
 
platforms
 
like
 
Facebook
 
provide
 
essential
 
emotional
 
support,
 
they
 
are
 
unregulated
 
and
 
often
 
fail
 
to
 
provide
 
precise,
 
legally
 
accurate
 
information
 
required
 
for
 
formal
 
dispute
 
resolution.
 
The
 
reliance
 
on
 
informal
 
advice
 
over
 
verified
 
statutes
 
highlights
 
a
 
systematic
 
failure;
 
as
 
Munoz
 
and
 
Munoz
 
(2024)
 
argue,
 
OFWs
 
struggle
 
to
 
comprehend
 
these
 
‘complex
 
legal
 
systems’
 
without
 
assistance,
 
creating
 
an
 
urgent
 
need
 
for
 
intelligent,
 
AI-driven
 
tools
 
capable
 
of
 
simplifying
 
complex
 
legal
 
frameworks
 
and
 
ensuring
 
workers
 
can
 
effectively
 
exercise
 
their
 
rights.
  
Problem  Statement  
Despite  the  established  vulnerability  of  the  nearly  200,000  Filipino  Domestic  Workers  
(FDWs)
 
in
 
Hong
 
Kong,
 
a
 
critical
 
disconnect
 
exists
 
between
 
the
 
statutory
 
protections
 
granted
 
by
 
the
 
Employment
 
Ordinance
 
and
 
the
 
workers'
 
actual
 
ability
 
to
 
access
 
justice.
 
The
 
current
 
ecosystem
 
of
 
legal
 
aid
 
fails
 
to
 
bridge
 
the
 
gap
 
between
 
high-level
 
policy
 
and
 
the
 
on-ground
 
reality
 
of
 
migrant
 
labor
 
due
 
to
 
the
 
inherent
 
limitations
 
of
 
both
 
traditional
 
human-centric
 
support
 
and
 
existing
 
digital
 
repositories.
 
Traditional
 
interventions,
 
such
 
as
 
the
 
Department
 
of
 
Migrant
 
Workers’
 
mobile
 
caravans,
 
rely
 
heavily
 
on
 
face-to-face
 
consultations;
 
while
 
effective
 
for
 
individual
 
cases,
 
this
 
model
 
is
 
inherently
 
unscalable,
 
restricted
 
to
 
a
 
“one-case-officer-to-one-worker”
 
ratio
 
(DFA,
 
2025).
 
Conversely,
 
digital
 
efforts
 
remain
 
passive
 
and
 
exclusionary,
 
as
 
government
 
portals
 
host
 
labor
 
laws
 
as
 
static
 
repositories
 
of
 
dense
 
legalese
 
written
 
at
 
a
 
post-graduate
 
reading
 
level,
 
effectively
 
acting
 
as
 
gatekeepers
 
rather
 
than
 
accessible
 
guides
 
for
 
non-expert
 
readers
 
(Bause
 
et
 
al.,
 
2024).
 
This  accessibility  gap  cannot  be  resolved  by  merely  adopting  off-the-shelf  Artificial  
Intelligence
 
solutions,
 
as
 
current
 
Large
 
Language
 
Models
 
(LLMs)
 
function
 
unreliably
 
within
 
the
 

===== PAGE 6 =====
5  legal  domain.  General-purpose  models  suffer  from  frequent  "jurisdictional  hallucinations,"  where  
the
 
system
 
may
 
cite
 
valid
 
laws
 
from
 
the
 
wrong
 
country
 
or
 
fabricate
 
provisions
 
entirely.
 
Benchmarking
 
reveals
 
that
 
generic
 
LLMs
 
hallucinate
 
legal
 
facts
 
between
 
69%
 
and
 
88%
 
of
 
the
 
time
 
when
 
asked
 
specific,
 
verifiable
 
legal
 
questions
 
(Dahl
 
et
 
al.,
 
2024).
 
Furthermore,
 
these
 
models
 
often
 
exhibit
 
"misgrounding,"
 
failing
 
to
 
distinguish
 
between
 
Philippine
 
protectionist
 
policies
 
and
 
Hong
 
Kong
 
labor
 
statutes
 
in
 
cross-border
 
disputes
 
(Guha
 
et
 
al.,
 
2023).
 
This
 
unreliability
 
creates
 
a
 
safety
 
hazard,
 
as
 
misinformation
 
in
 
labor
 
law
 
can
 
lead
 
to
 
immediate
 
loss
 
of
 
employment
 
or
 
visa
 
status
 
for
 
vulnerable
 
migrants.
 
The  problem  is  further  compounded  by  a  "triple  threat"  of  systemic  technical  barriers  that  
render
 
standard
 
NLP
 
tools
 
ineffective
 
for
 
this
 
specific
 
demographic.
 
First,
 
a
 
Linguistic
 
Misalignment
 
exists
 
because
 
OFWs
 
frequently
 
articulate
 
concerns
 
in
 
code-switched
 
vernacular
 
(Taglish),
 
which
 
standard
 
NLP
 
models
 
fail
 
to
 
parse,
 
leading
 
to
 
semantic
 
retrieval
 
failures
 
(Jose
 
&
 
Oco,
 
2022).
 
Second,
 
the
 
"Legalese"
 
Barrier
 
ensures
 
that
 
even
 
when
 
documents
 
are
 
retrieved,
 
the
 
complexity
 
of
 
the
 
statutory
 
language
 
remains
 
unintelligible
 
without
 
simplification
 
that
 
preserves
 
legal
 
nuance.
 
Third,
 
a
 
Dual-Jurisdiction
 
Conflict
 
arises
 
where
 
generic
 
AI
 
fails
 
to
 
contextualize
 
which
 
legal
 
framework
 
applies
 
to
 
a
 
specific
 
contract
 
situation.
 
Consequently,
 
the
 
general
 
problem
 
this
 
study
 
seeks
 
to
 
address
 
is
 
the
 
absence
 
of
 
an
 
accessible,
 
legally
 
grounded
 
assistance
 
tool
 
tailored
 
to
 
the
 
sociolinguistic
 
profile
 
of
 
OFWs
 
in
 
Hong
 
Kong.
 
There
 
is
 
currently
 
no
 
mechanism
 
that
 
successfully
 
combines
 
hallucination-resistant
 
legal
 
reasoning
 
with
 
the
 
linguistic
 
adaptability
 
required
 
to
 
interpret
 
code-switched
 
inquiries,
 
leaving
 
workers
 
dependent
 
on
 
unverified
 
social
 
media
 
advice
 
or
 
unscalable
 
manual
 
support.
 
Objectives  of  the  Study  
The  primary  objective  of  this  research  is  to  design  and  evaluate  a  Context-Aware  
Adaptive
 
Routing
 
Framework
 
that
 
addresses
 
the
 
"triple
 
threat"
 
of
 
linguistic
 
barriers,
 
dual-jurisdiction
 
conflict,
 
and
 
legal
 
complexity
 
faced
 
by
 
Overseas
 
Filipino
 
Workers
 
(OFWs).
 
Unlike
 
standard
 
chatbots,
 
this
 
study
 
aims
 
to
 
engineer
 
a
 
system
 
that
 
dynamically
 
adjusts
 
its
 
retrieval
 
and
 
reasoning
 
strategies
 
based
 
on
 
the
 
user's
 
literacy
 
level
 
and
 
legal
 
context,
 
thereby
 
mitigating
 
the
 
hallucination
 
risks
 
inherent
 
in
 
general-purpose
 
Large
 
Language
 
Models
 
(LLMs).
 
Specific  Objectives:  
 
1.  To  develop  a  Context-Aware  Routing  Framework  that  will  support  the  existing  
LLM
 
models.
 2.  To  adapt  a  Literacy-Adaptive  Safety  Mechanism  to  facilitate  the  output  of  the  
routing
 
mechanism.
 3.  To  evaluate  system  performance  via  Automated  Metrics  4.  To  validate  reliability  via  Expert  Assessment  

===== PAGE 7 =====
6  Project  Scope  Given  the  extensive  and  complex  nature  of  labor  law,  this  project  will  employ  a  
systematic,
 
data-driven
 
methodology
 
to
 
define
 
a
 
feasible
 
research
 
domain.
 
Specifically,
 
researchers
 
will
 
utilize
 
Topic
 
Modeling
 
on
 
a
 
comprehensive
 
corpus
 
of
 
labor
 
law
 
forums
 
and
 
frequently
 
asked
 
questions
 
to
 
identify
 
and
 
prioritize
 
high-frequency
 
versus
 
low-frequency
 
topics.
 
The
 
distinct
 
topical
 
landscape
 
revealed
 
by
 
this
 
analysis
 
will
 
formally
 
delineate
 
the
 
final
 
scope
 
and
 
domain
 
of
 
this
 
research,
 
ensuring
 
that
 
the
 
project
 
remains
 
focused
 
and
 
achievable
 
within
 
the
 
university's
 
prescribed
 
timeline.
 
Data  Sources  As  stated  above,  researchers  narrowed  down  the  scope  of  our  study  to  certain  topics  that  
OFWs
 
are
 
commonly
 
concerned
 
about.
 
To
 
achieve
 
this,
 
researchers
 
are
 
to
 
perform
 
topic
 
modeling
 
using
 
social
 
media
 
posts
 
(such
 
as
 
Reddit,
 
forums,
 
and
 
Facebook
 
pages).
 
From
 
there,
 
researchers
 
would
 
identify
 
topics
 
that
 
are
 
commonly
 
discussed,
 
which
 
would
 
constitute
 
the
 
scope
 
of
 
our
 
studies.
 
Discussions
 
and/or
 
forums
 
posted
 
within
 
5
 
years
 
(2020-2025)
 
would
 
be
 
extracted
 
as
 
datasets
 
to
 
maintain
 
relevance.
 
After
 
identifying
 
the
 
topics,
 
researchers
 
will
 
then
 
extract
 
the
 
corpora
 
from
 
webpages
 
where
 
labor
 
laws
 
of
 
host
 
nations
 
(written
 
in
 
Chinese,
 
regardless
 
of
 
the
 
presence
 
of
 
English
 
annotations)
 
were
 
concerned.
 
 
Language  Handling  Our  chosen  LLM  will  support  Filipino,  Taglish,  and  English.  Instead  of  fine-tuning,  
researchers
 
will
 
rely
 
on
 
an
 
existing
 
high-capacity
 
multilingual
 
model.
  Researchers  adhere  to  guidelines  for  human-AI  interaction,  which  emphasize  that  
AI-infused
 
systems
 
should
 
clearly
 
communicate
 
their
 
capabilities,
 
explain
 
uncertainty,
 
allow
 
users
 
to
 
correct
 
errors,
 
and
 
adapt
 
over
 
time
 
(Amershi
 
et
 
al.,
 
2019).
 
Additionally,
 
ethical
 
AI
 
frameworks
 
stress
 
the
 
importance
 
of
 
privacy,
 
transparency,
 
and
 
fairness
 
in
 
algorithmic
 
decision-making
 
(Lepri,
 
Oliver,
 
&
 
Pentland,
 
2021).
  Limitations  of  the  Study    The  validity  of  the  proposed  RAG  system  will  be  intrinsically  bound  to  the  temporal  
currency
 
of
 
its
 
legal
 
corpus.
 
As
 
legal
 
frameworks
 
evolve,
 
the
 
system’s
 
accuracy
 
will
 
be
 
limited
 
by
 
the
 
frequency
 
of
 
manual
 
updates
 
and
 
expert
 
oversight
 
(Agada
 
et
 
al.,
 
2025).
 
This
 
constraint
 
will
 
be
 
particularly
 
critical
 
for
 
labor
 
law
 
applications,
 
where
 
new
 
administrative
 
guidelines
 
or
 
amendments
 
to
 
the
 
Hong
 
Kong
 
Employment
 
Ordinance
 
could
 
instantly
 
alter
 
worker
 
entitlements.
 
Consequently,
 
if
 
the
 
corpus
 
is
 
not
 
synchronized
 
in
 
real-time,
 
the
 
system
 
will
 
risk
 
retrieving
 
outdated
 
clauses,
 
leading
 
to
 
outputs
 
that
 
diverge
 
from
 
the
 
prevailing
 
legal
 
reality.
  Technical  limitations  will  also  arise  regarding  retrieval  granularity  and  document  
mismatch.
 
Consistent
 
with
 
findings
 
by
 
Reuter
 
et
 
al.
 
(2025),
 
the
 
system
 
will
 
face
 
challenges
 
in
 
distinguishing
 
between
 
specific
 
legal
 
provisions
 
and
 
the
 
repetitive
 
boilerplate
 
language
 
common
 
in
 
legal
 
statutes.
 
This
 
structural
 
similarity
 
will
 
introduce
 
a
 
margin
 
of
 
error
 
where
 
the
 
model
 
may
 

===== PAGE 8 =====
7  retrieve  contextually  similar  but  legally  distinct  text  chunks,  potentially  affecting  the  precision  of  
the
 
generated
 
legal
 
advice.
  Furthermore,  the  study  will  delimit  the  utility  of  User  Profiles;  these  will  function  strictly  
as
 
contextual
 
instructions
 
for
 
the
 
reasoning
 
pipeline
 
and
 
scenario-based
 
validation
 
tools,
 
rather
 
than
 
as
 
dynamic
 
training
 
data.
 
By
 
anchoring
 
the
 
chatbot
 
persona
 
as
 
a
 
fixed,
 
empathetic
 
guide
 
for
 
vulnerable
 
OFWs,
 
the
 
research
 
will
 
prioritize
 
safety
 
and
 
consistency
 
over
 
adaptive
 
learning.
 
This
 
alignment
 
with
 
human-centered
 
AI
 
principles
 
(Amershi
 
et
 
al.,
 
2019;
 
ISO/IEC
 
TR
 
24028:2020)
 
will
 
ensure
 
that
 
the
 
system
 
maintains
 
a
 
transparent
 
and
 
professional
 
tone,
 
preventing
 
the
 
model
 
from
 
incorporating
 
potentially
 
erroneous
 
user
 
inputs
 
into
 
its
 
knowledge
 
base.
 
Hypothesis    The  integration  of  a  context-aware  adaptive  framework  consisting  of  input  analysis,  legal  
reasoning,
 
and
 
safety-audited
 
style
 
adaptation
 
will
 
improve
 
the
 
accuracy
 
and
 
clarity
 
of
 
labor-law
 
explanations
 
for
 
OFWs.
 
The
 
system
 
first
 
performs
 
semantic
 
and
 
linguistic
 
analysis
 
to
 
detect
 
language,
 
intent,
 
and
 
jurisdiction
 
in
 
user
 
queries
 
expressed
 
in
 
Taglish
 
or
 
English.
 
It
 
then
 
processes
 
the
 
query
 
through
 
a
 
dual-jurisdiction
 
legal
 
engine
 
that
 
retrieves,
 
aligns,
 
and
 
interprets
 
relevant
 
Philippine
 
and
 
host-country
 
labor
 
laws.
 
Finally,
 
a
 
safety
 
audit
 
and
 
literacy-adaptive
 
style
 
transfer
 
layer
 
ensure
 
that
 
responses
 
are
 
legally
 
grounded,
 
comprehensible,
 
and
 
consistent
 
with
 
the
 
user’s
 
linguistic
 
context.
   It  is  hypothesized  that  the  combination  of  semantic  awareness,  multi-jurisdiction  
reasoning,
 
and
 
safety-audited
 
style
 
adaptation
 
will
 
significantly
 
reduce
 
legal
 
hallucinations
 
and
 
misinterpretations
 
compared
 
to
 
baseline
 
LLMs.
 
By
 
dynamically
 
routing
 
and
 
validating
 
each
 
response
 
through
 
these
 
specialized
 
modules,
 
the
 
proposed
 
framework
 
is
 
expected
 
to
 
deliver
 
legally
 
faithful,
 
contextually
 
grounded,
 
and
 
user-appropriate
 
explanations
 
that
 
enhance
 
OFWs’
 
understanding
 
of
 
their
 
labor
 
rights.
  II.  Research  Framework   Conceptual  Framework                 Figure  1:  Input-Process-Output  model  of  the  conceptual  framework   


===== PAGE 9 =====
8   The  study  follows  an  Input-Process-Output  (IPO)  model  to  structure  the  development  of  
the
 
adaptive
 
routing
 
framework
 
chatbot.
 
The
 
input
 
phase
 
consists
 
of
 
aggregating
 
a
 
comprehensive
 
dual-jurisdiction
 
Labor
 
Law
 
Corpus
 
covering
 
the
 
Philippines
 
and
 
the
 
host
 
country,
 
Hong
 
Kong.
 
Another
 
input
 
would
 
be
 
the
 
Migrant
 
Workers
 
FAQs
 
Corpus
 
derived
 
from
 
community
 
forum
 
discussions.
 
These
 
datasets
 
feed
 
into
 
the
 
Process
 
phase,
 
which
 
begins
 
with
 
Topic
 
Modeling
 
to
 
delineate
 
the
 
scope
 
of
 
the
 
research
 
study
 
while
 
prioritizing
 
high-priority
 
legal
 
concerns,
 
followed
 
by
 
the
 
technical
 
development
 
of
 
the
 
Context-Aware
 
Adaptive
 
Routing
 
Framework.
 
This
 
phase
 
also
 
integrates
 
an
 
iterative
 
Expert
 
Validation
 
and
 
Evaluation
 
Loop
 
to
 
ensure
 
the
 
system’s
 
legal
 
accuracy
 
and
 
safety.
 
In
 
the
 
output
 
phase,
 
delivering
 
the
 
functional
 
Adaptive
 
Routing
 
Framework
 
Chatbot
 
designed
 
for
 
OFWs,
 
alongside
 
empirical
 
Performance
 
metrics
 
that
 
quantify
 
the
 
system’s
 
effectiveness,
 
retrieval
 
accuracy,
 
and
 
token
 
efficiency
 
over
 
time.
  III.  Significance  of  the  Study   This  study  will  bridge  the  critical  gap  between  complex  legal  frameworks  and  the  
vulnerable
 
population
 
of
 
Filipino
 
Domestic
 
Workers
 
(FDWs)
 
in
 
Hong
 
Kong.
 
By
 
leveraging
 
Natural
 
Language
 
Processing
 
(NLP)
 
to
 
democratize
 
legal
 
information,
 
this
 
research
 
will
 
create
 
immediate
 
value
 
for
 
migrant
 
workers
 
while
 
addressing
 
significant
 
gaps
 
in
 
academic
 
theory
 
and
 
social
 
policy.
  Anchored  in  the  UN  Sustainable  Development  Goals,  this  research  will  primarily  
operationalize
 
SDG
 
8
 
(Decent
 
Work
 
and
 
Economic
 
Growth),
 
specifically
 
Target
 
8.8,
 
by
 
utilizing
 
NLP
 
to
 
demystify
 
the
 
Hong
 
Kong
 
Employment
 
Ordinance.
 
This
 
will
 
act
 
as
 
a
 
preventative
 
mechanism
 
against
 
exploitation,
 
clarifying
 
labor
 
rights
 
and
 
responsibilities
 
to
 
ensure
 
a
 
secure
 
working
 
environment.
 
Concurrently,
 
the
 
study
 
will
 
advance
 
SDG
 
16.3
 
(Access
 
to
 
Justice)
 
by
 
dismantling
 
the
 
barrier
 
of
 
"legalese";
 
it
 
will
 
transform
 
complex
 
statutes
 
into
 
accessible,
 
context-aware
 
content,
 
thereby
 
facilitating
 
genuine
 
legal
 
literacy.
 
Furthermore,
 
the
 
research
 
will
 
foster
 
social
 
inclusion
 
under
 
SDG
 
10.2
 
(Reduced
 
Inequalities),
 
leveling
 
the
 
power
 
asymmetry
 
between
 
employers
 
and
 
domestic
 
workers
 
by
 
ensuring
 
legal
 
knowledge
 
will
 
be
 
a
 
shared
 
resource
 
rather
 
than
 
an
 
exclusive
 
privilege.
  The  immediate  significance  will  extend  to  the  nearly  200,000  Filipino  Domestic  Workers  
in
 
Hong
 
Kong,
 
providing
 
them
 
with
 
24/7,
 
reliable
 
legal
 
interpretation
 
that
 
will
 
reduce
 
dependency
 
on
 
inaccurate
 
informal
 
advice
 
networks.
 
By
 
validating
 
their
 
rights
 
regarding
 
termination,
 
wages,
 
and
 
holidays,
 
the
 
tool
 
will
 
empower
 
workers
 
to
 
navigate
 
the
 
host
 
environment
 
with
 
confidence.
 
For
 
support
 
institutions
 
like
 
the
 
Department
 
of
 
Migrant
 
Workers
 
(DMW)
 
and
 
NGOs,
 
this
 
technology
 
will
 
function
 
as
 
a
 
scalable
 
"legal
 
triage"
 
system.
 
By
 
automating
 
responses
 
to
 
routine
 
inquiries,
 
it
 
will
 
optimize
 
resource
 
allocation,
 
allowing
 
advocates
 
to
 
concentrate
 
human
 
capital
 
on
 
severe
 
cases
 
requiring
 
direct
 
legal
 
intervention.
  ●  Academically,  this  research  will  address  a  distinct  gap  in  Legal  NLP,  which  
traditionally
 
favors
 
English-centric,
 
high-level
 
contract
 
review.
 
It
 
will
 
pioneer
 
"Legal
 
AI
 
for
 
the
 
Layman"
 
by
 
proposing
 
a
 
context-aware
 
framework
 
capable
 
of
 
processing
 
code-switching
 
(Taglish),
 
thereby
 
shifting
 
methodological
 
norms
 

===== PAGE 10 =====
9  toward  sociolinguistic-aware  AI.  On  a  policy  level,  the  study  will  advocate  a  
transition
 
from
 
reactive
 
protection
 
to
 
proactive
 
empowerment.
 
The
 
findings
 
will
 
provide
 
a
 
technical
 
blueprint
 
for
 
integrating
 
AI-driven
 
legal
 
literacy
 
into
 
pre-deployment
 
initiatives,
 
such
 
as
 
the
 
Pre-Departure
 
Orientation
 
Seminar
 
(PDOS),
 
ensuring
 
workers
 
will
 
be
 
legally
 
equipped
 
prior
 
to
 
migration.
   CHAPTER  2   Research  Design  and  Methodology  Upon  realizing  the  rationale  and  status  quo  of  OFWs  working  in  Hong  Kong,  we  
recognize
 
the
 
motivation
 
and
 
advocate
 
for
 
bridging
 
the
 
interpretation
 
of
 
legal
 
law
 
using
 
AI,
 
enhancing
 
their
 
familiarity
 
with
 
resolving
 
issues
 
and
 
disputes
 
in
 
working
 
environments.
 
The
 
next
 
step
 
for
 
the
 
project
 
to
 
come
 
into
 
fruition
 
is
 
to
 
set
 
up
 
a
 
framework,
 
guiding
 
us
 
on
 
how
 
far
 
it
 
will
 
reach
 
within
 
time
 
and
 
financial
 
constraints,
 
as
 
well
 
as
 
justifying
 
the
 
product’s
 
feasibility
 
given
 
the
 
adherence
 
to
 
standard
 
procedures
 
in
 
certain
 
fields
 
of
 
study,
 
such
 
as
 
data
 
analysis
 
and
 
Artificial
 
Intelligence.
 
4.1  Data  Acquisition  and  Preparation  The  researchers  will  collect  public  posts  from  known  online  forums,  social  media  
platforms,
 
and
 
news
 
sites
 
where
 
OFWs
 
discuss
 
work-related
 
experiences
 
(2020-2025).
 
These
 
posts
 
will
 
inform
 
our
 
topic-modelling
 
analysis
 
and
 
help
 
define
 
the
 
domain
 
of
 
our
 
summarization
 
and
 
NLI
 
tasks.
 
In
 
parallel,
 
the
 
researchers
 
will
 
compile
 
a
 
corpus
 
of
 
labour-law
 
documents
 
and
 
employment
 
contract
 
templates
 
from
 
official
 
Philippine
 
government
 
agencies,
 
international
 
conventions,
 
and
 
verified
 
legal
 
databases.
 
Only
 
posts
 
explicitly
 
referencing
 
labour
 
issues
 
will
 
be
 
retained;
 
personal
 
data
 
unrelated
 
to
 
the
 
problem
 
domain
 
will
 
be
 
removed
 
to
 
protect
 
privacy.
 
  The  researchers  will  build  our  knowledge  base  from  (a)  Philippine  and  international  
labour-law
 
documents,
 
including
 
statutes,
 
regulations,
 
and
 
bilateral
 
agreements;
 
(b)
 
employment
 
contracts
 
templates;
 
and
 
(c)
 
annotated
 
examples
 
from
 
ContractNLI
 
and
 
similar
 
datasets.
 
Forum
 
and
 
social
 
media
 
data
 
will
 
be
 
scraped
 
in
 
compliance
 
with
 
platform
 
policies
 
and
 
anonymised.
 
The
 
PIDS
 
policy
 
note
 
discloses
 
the
 
need
 
for
 
improved
 
dissemination
 
of
 
health
 
and
 
social-security
 
information
 
among
 
OFWs;
 
thus,
 
we
 
will
 
prioritize
 
sources
 
that
 
explain
 
entitlements
 
to
 
health,
 
social-security,
 
and
 
welfare
 
benefits.
  The  corpora  required  in  this  study  would  then  be  fed  into  the  model,  where  language  
inference
 
is
 
performed
 
along
 
with
 
the
 
use
 
of
 
Retrieval-Augmentation-Generation
 
(RAG)
 
since
 
the
 
ever-changing
 
nature
 
of
 
laws
 
over
 
the
 
years.
 
This
 
approach
 
aligns
 
closely
 
with
 
the
 
framework
 
proposed
 
by
 
Oza,
 
J.,
 
&
 
Yadav,
 
H.
 
(2023,
 
December
 
14).
  As  a  result,  a  chatbot  would  then  be  created  to  validate  the  effectiveness  of  the  chatbot,  
which
 
translates
 
Chinese
 
law
 
documents
 
into
 
either
 
English
 
or
 
Tagalog,
 
then
 
summarizes
 
the
 
long
 
legal
 
document
 
into
 
precise
 
and
 
concise
 
sentences
 
that
 
are
 
more
 
understandable.
 
 

===== PAGE 11 =====
10  4.2  System  Architecture  Modules  These  are  the  step-by-step  implementation  of  the  researchers  during  the  methodology  
phase
 
based
 
on
 
the
 
objectives
 
stated
 
above.
 
4.3  Document-Based  Comparative  Analysis   
This  study  will  conduct  a  document-based  comparative  analysis  of  state-of-the-art  models  
released
 
by
 
major
 
AI
 
developers,
 
OpenAI,
 
Anthropic,
 
DeepSeek,
 
Google
 
AI,
 
and
 
Meta,
 
using
 
their
 
publicly
 
available
 
research
 
papers,
 
model
 
cards,
 
and
 
benchmark
 
reports.
 
The
 
analysis
 
will
 
examine
 
each
 
model’s
 
documented
 
strengths,
 
limitations,
 
and
 
redundancies
 
in
 
linguistic
 
processing,
 
retrieval
 
accuracy,
 
reasoning
 
stability,
 
and
 
safety
 
performance.
 
Rather
 
than
 
re-running
 
computationally
 
expensive
 
evaluations,
 
the
 
study
 
relies
 
on
 
authoritative
 
technical
 
benchmarks
 
reported
 
in
 
these
 
releases,
 
which
 
align
 
with
 
recent
 
LLM
 
capability
 
assessments
 
(OpenAI,
 
2024;
 
Anthropic,
 
2024;
 
Google
 
DeepMind,
 
2024).
 
The
 
insights
 
derived
 
from
 
this
 
analysis
 
will
 
inform
 
the
 
architectural
 
design
 
and
 
model-selection
 
requirements
 
of
 
the
 
proposed
 
multi-model
 
routing
 
framework.
 
4.3.1  Multi-Head  Classifier  for  Code-Switched  Queries  To  develop  a  linguistic  normalization  module  capable  of  accurately  detecting  intent  and  
jurisdiction
 
within
 
code-switched
 
(Taglish)
 
and
 
low-literacy
 
user
 
queries,
 
ensuring
 
semantic
 
alignment
 
before
 
legal
 
retrieval,
 
we
 
are
 
to
 
use
 
Linguistic
 
Code-switching
 
Evaluation
 
(LinCE)
  
similar
 
to
 
one
 
made
 
by
 
Aguilar
 
et.al.
 
(2020),
 
but
 
our
 
corpora
 
will
 
cover
 
only
 
be
 
Taglish
 
language
 
pair,
 
for
 
better
 
benchmarking
 
when
 
normalized
 
to
 
English,
 
as
 
Filipino
 
support
 
is
 
lacking,
 
causing
 
performance
 
gaps,
 
as
 
stated
 
by
 
Montelo
 
et.al.
 
(2025)
 
4.3.2  Dual-Jurisdiction  Retrieval  Pipeline  
 Retrieval-augmented  techniques  significantly  enhance  factual  grounding  and  lessen  
hallucinations
 
by
 
combining
 
external
 
knowledge
 
retrieval
 
with
 
generative
 
models.
 
To
 
engineer
 
a
 
Dual-Jurisdiction
 
Pipeline,
 
the
 
system
 
will
 
employ
 
a
 
Split-Track
 
RAG
 
architecture
 
that
 
classifies
 
queries
 
and
 
routes
 
them
 
either
 
into
 
single-jurisdiction
 
retrieval
 
paths
 
for
 
routine
 
procedural
 
questions
 
or
 
dual-jurisdiction
 
paths
 
for
 
complex
 
cross-border
 
disputes
 
(Lewis
 
et
 
al,
 
2020;
 
Pipitone
 
&
 
Alami
 
2024).
 
Split-track
 
routing
 
is
 
valuable
 
for
 
multi-jurisdictional
 
legal
 
reasoning,
 
and
 
adaptive
 
RAG
 
Frameworks
 
that
 
adjust
 
retrieval
 
strategies
 
to
 
query
 
complexity
 
further
 
improve
 
efficiency
 
and
 
accuracy
 
(Jeong
 
et
 
al.
 
2024;
 
Kalra
 
et
 
al.
 
2024).
 
4.3.3  Literacy-Adaptive  Safety  Layer  
To  implement  a  Literacy-Adaptive  Safety  Layer,  the  system  will  apply  a  post-generation  
audit
 
mechanism
 
that
 
simplifies
 
legal
 
outputs
 
into
 
an
 
Accessible
 
Language
 
and
 
Clarity
 
(ALAC)
 
format.
 
The
 
ALAC
 
format
 
was
 
adopted
 
to
 
address
 
variability
 
in
 
user
 
literacy
 
and
 
its
 
impact
 
on
 
trust,
 
comprehension,
 
and
 
safe
 
use
 
of
 
AI-generated
 
legal
 
content.
 
Prior
 
studies
 
indicate
 
that
 
users
 
are
 
more
 
likely
 
to
 
trust
 
and
 
correctly
 
interpret
 
AI
 
outputs
 
when
 
information
 
is
 
presented
 
in
 
clear,
 
accessible
 
language
 
rather
 
than
 
dense
 
technical
 
prose.
 
To
 
apply
 
ALAC,
 
a
 
case
 
study
 
will
 
be
 
conducted
 
in
 
which
 
legal
 
outputs
 
are
 
reviewed
 
and
 
simplified
 
through
 
prompt
 
engineering
 

===== PAGE 12 =====
11  developed  in  collaboration  with  domain  experts.  This  ensures  that  simplification  preserves  legal  
meaning
 
while
 
improving
 
clarity.
 
By
 
aligning
 
language
 
accessibility
 
with
 
expert-validated
 
prompts,
 
ALAC
 
functions
 
as
 
a
 
safety
 
and
 
trust-calibration
 
mechanism
 
that
 
reduces
 
misinterpretation
 
risks
 
without
 
compromising
 
legal
 
accuracy.
 
 
4.3.4  Quantifying  Computational  and  Hallucination  Performance  
To                 verify  the  reliability  of  the  system  through  an  Expert  Human-in-the-Loop  assessment,  
the
 
research
 
will
 
engage
 
in
 
a
 
blind
 
evaluation
 
with
 
legal
 
practitioners
 
and
 
OFW
 
case
 
officers.
 
They
 
will
 
judge
 
the
 
outputs
 
in
 
terms
 
of
 
Substantive
 
Legal
 
Correctness,
 
Jurisdictional
 
Accuracy,
 
and
 
Safety/Risk
 
Mitigation.
 
Human-expert
 
confirmation
 
is
 
very
 
important
 
in
 
AI
 
for
 
critical
 
situations
 
as
 
it
 
understands
 
the
 
contextual
 
nuances,
 
pinpoints
 
domain-specific
 
errors,
 
and
 
thus,
 
increases
 
the
 
trust
 
in
 
system
 
outputs
 
(Myllyaho
 
et
 
al.
 
2021).
 
A
 
study
 
on
 
this
 
matter
 
has
 
found
 
that
 
well-organized
 
expert
 
supervision
 
leads
 
to
 
better
 
safety
 
standards
 
and
 
fewer
 
risks
 
being
 
overlooked,
 
which
 
cannot
 
be
 
detected
 
by
 
benchmark-only
 
testing
 
(Ibrahim
 
et
 
al.
 
2024).
 
New
 
HITL
 
models
 
also
 
show
 
that
 
the
 
real-world
 
reliability
 
and
 
decision
 
quality
 
are
 
greatly
 
improved
 
when
 
expert
 
judgment
 
is
 
combined
 
with
 
AI
 
outputs
 
(European
 
Journal
 
of
 
Computer
 
Science
 
and
 
Information
 
Technology
 
                2025).
 
4.3.5  Validate  System  Reliability  through  Expert  Human-in-the-Loop  (HitL)  Assessment   To  validate  system  reliability  through  Expert  Human-in-the-Loop  (HitL)  assessment,  the  
study
 
will
 
conduct
 
a
 
blind
 
evaluation
 
with
 
legal
 
practitioners
 
and
 
OFW
 
case
 
officers
 
to
 
assess
 
outputs
 
on
 
Substantive
 
Legal
 
Correctness,
 
Jurisdiction
 
Accuracy,
 
and
 
Safety/Risk
 
Mitigation.
 
Previous
 
studies
 
stressed
 
that
 
expert-driven
 
validation
 
is
 
crucial
 
for
 
assessing
 
AI
 
systems
 
in
 
significant
 
areas,
 
since
 
it
 
takes
 
into
 
account
 
contextual
 
judgment,
 
legal
 
nuance,
 
and
 
safety
 
risks
 
that
 
automated
 
benchmarks
 
cannot
 
reliably
 
detect
 
(Myllyaho
 
et
 
al.,
 
2021;
 
Ibrahim
 
et
 
al.,
 
2024).
 
Additionally,
 
human-centered
 
evaluation
 
frameworks
 
have
 
shown
 
that
 
the
 
presence
 
of
 
HitL
 
monitoring
 
increases
 
system
 
trustworthiness
 
and
 
applicability
 
to
 
real-world
 
situations
 
in
 
complex
 
decision-making
 
environments
 
(European
 
Journal
 
of
 
Computer
 
Science
 
and
 
Information
 
Technology,
 
2025).
 
4.4  Evaluation  Framework  &  Benchmarking  This  study  employs  a  rigorous  Mixed-Methods  Evaluation  Strategy  to  validate  the  
proposed
 
Context-Aware
 
Legal
 
Retrieval
 
System.
 
Recognizing
 
that
 
standard
 
software
 
metrics
 
often
 
fail
 
to
 
capture
 
the
 
nuances
 
of
 
high-stakes
 
legal
 
reasoning
 
(Chang
 
et
 
al.,
 
2024),
 
the
 
framework
 
integrates
 
automated
 
computational
 
benchmarking
 
with
 
a
 
"Gold
 
Standard"
 
human-expert
 
validation
 
process.
 
This
 
dual
 
approach
 
ensures
 
that
 
the
 
system
 
is
 
assessed
 
not
 
only
 
for
 
technical
 
efficiency
 
but
 
for
 
substantive
 
legal
 
safety
 
and
 
sociolinguistic
 
appropriateness.
 

===== PAGE 13 =====
12   
4.4.1  Establishment  of  Groundtruth  for  Evaluation  Metrics   Evaluating  the  proposed  pipeline  performance  is  crucial  for  understanding  the  capability  
of
 
the
 
proposed
 
framework;
 
therefore,
 
establishing
 
a
 
validation
 
dataset
 
is
 
required.
 
The
 
dataset
 
will
 
cover
 
the
 
assessment
 
of
 
all
 
three
 
components
 
of
 
the
 
said
 
pipeline,
 
including
 
scenario-based
 
legal
 
query
 
examples,
 
pipeline
 
outputs,
 
expected
 
answers
 
and
 
expert
 
annotations.
 
Previous
 
Research
 
on
 
Retrieval-Augmented
 
Generation
 
(RAG)
 
emphasizes
 
the
 
importance
 
of
 
incorporating
 
recent
 
or
 
updated
 
documents
 
as
 
temporal-sensitive
 
studies
 
such
 
as
 
ChronoQA
 
and
 
Temporal
 
GraphRAG
 
demonstrate
 
that
 
RAG
 
systems
 
experience
 
accuracy
 
degradation
 
when
 
evaluated
 
only
 
on
 
a
 
static
 
corpora,
 
thus
 
requiring
 
the
 
corpora
 
to
 
be
 
updated
 
frequently
 
(Chen
 
et
 
al.,
 
2025;
 
Han
 
et
 
al.,
 
2025).
 
Similarly,
 
research
 
on
 
multi-step
 
reasoning
 
highlights
 
that
 
complex
 
scenario-based
 
queries
 
are
 
essential
 
for
 
evaluating
 
models'
 
ability
 
to
 
integrate
 
multiple
 
sources
 
of
 
evidence
 
to
 
further
 
expose
 
limitations
 
that
 
simple
 
queries
 
cannot
 
identify
 
(Lee
 
et
 
al.,
 
2025;
 
Zhu
 
et
 
al.,
 
2022;
 
Java
 
et
 
al.,
 
2025).
 
Meanwhile,
 
RAG
 
evaluation
 
surveys
 
and
 
adaptive
 
retrieval
 
studies
 
emphasize
 
that
 
simple
 
factual
 
queries
 
remain
 
necessary
 
for
 
benchmarking
 
baseline
 
retrieval
 
precision
 
before
 
assessing
 
high-level
 
inference
 
performance
 
(Gao
 
et
 
al.,
 
2024).
  Based  on  these  findings,  the  validation  dataset  in  this  study  adopts  a  balance  composition  
of
 
25%
 
recent
 
or
 
updated
 
labor
 
law
 
clauses,
 
25%
 
simple
 
factual
 
Q/A
 
queries,
 
and
 
50%
 
complex
 
multi-step
 
legal
 
scenarios,
 
covering
 
a
 
comprehensive
 
assessment
 
of
 
retrieval
 
adaptability,
 
factual
 
grounding,
 
and
 
NLI-based
 
reasoning.
  For  the  assurance  of  individual  bias,   cross-validation  will  be  performed  by  multiple  
independent
 
panels
 
of
 
legal
 
experts
 
with
 
whom
 
the
 
researchers
 
have
 
established
 
formal
 
partnerships.
  1.  SOL  (School  of  Law,  Saint  Louis  University):  Faculty  members  and  legal  researchers  
familiar
 
with
 
Philippine
 
labor
 
law
 
and
 
international
 
worker
 
protections.
 2.  DMW  (Department  of  Migrant  Workers,  Philippines):  Case  officers  and  policy  analysts  
who
 
handle
 
OFW
 
complaints
 
and
 
provide
 
frontline
 
legal
 
guidance
 
and
 
Pilot
 
Testing.
 3.  UPD  (University  of  the  Philippines  Diliman,  College  of  Law):  Juris  Doctor  (J.D.)  and  
Bachelor
 
of
 
Laws
 
(LL.B.)
 
graduates
 
specializing
 
in
 
labor
 
and
 
migrant
 
rights
 
law.
             

===== PAGE 14 =====
13  Table  1.  Sample  Data  Record  of  Data  Validation  
This  annotated  validation  dataset  will  serve  as  the  benchmark  for  comparative  evaluation  
between
 
our
 
proposed
 
context-aware,
 
multi-model
 
routing
 
framework
 
and
 
vanilla
 
LLMs
 
(e.g.,
 
GPT-4,
 
Claude
 
3,
 
Gemini
 
2.5).
 
Performance
 
will
 
be
 
measured
 
using
 
both
 
automated
 
metrics
 
(
 
hallucination
 
rate
 
and
 
token
 
cost
 
efficiency)
 
and
 
human
 
expert
 
scores
 
across
 
the
 
six
 
columns
 
defined
 
in
 
Table
 
1.
 
This
 
dual
 
approach
 
enables
 
us
 
to
 
quantify
 
improvements
 
in
 
accuracy,
 
clarity,
 
and
 
jurisdictional
 
reliability
 
over
 
standard
 
generative
 
AI
 
tools.
  In  the  study  of  Silveira  et  al.  (2014),  “A  Gold  Standard  Dependency  Corpus  for  English”  
demonstrated
 
the
 
use
 
of
 
gold
 
standard
 
annotations
 
using
 
the
 
Stanford
 
Dependencies
 
standard
 
to
 
address
 
the
 
scarcity
 
of
 
low-quality
 
corpora
 
for
 
English,
 
as
 
well
 
as
 
the
 
limited
 
resources
 
of
 
syntactic
 
annotations
 
for
 
informal
 
genres
 
of
 
English
 
text.
 
Thus,
 
our
 
proposed
 
pipeline
 
evaluation
 
requires
 
expert
 
annotation
 
that
 
demands
 
a
 
required
 
level
 
of
 
expertise
 
or
 
domain
 
mastery,
 
requiring
 
a
 
panel
 
of
 
experts
 
defined
 
as
 
a
 
Juris
 
Doctor
 
(J.D.)
 
or
 
Bachelor
 
of
 
Laws
 
(LL.B.)
 
degree
 
to
 
ensure
 
a
 
gold
 
standard
 
conclusion.
 
(International
 
Organization
 
for
 
Standardization,
 
2020).
 
4.4.2  Benchmarking  (Our  model  vs  Vanilla  LLMs)  
To  demonstrate  the  superior  safety  and  accuracy  of  the  proposed  Context-Aware  Legal  
Chatbot
 
over
 
"Vanilla
 
AI"
 
baselines
 
(e.g.,
 
OpenAI,
 
Anthropic,
 
DeepSeek),
 
we
 
propose
 
a
 
comparative
 
benchmarking
 
framework
 
validated
 
by
 
a
 
panel
 
of
 
licensed
 
legal
 
practitioners
 
and
 
labor
 
rights
 
advocates.
 
This
 
expert-led
 
approach
 
addresses
 
the
 
limitations
 
of
 
automated
 
metrics
 
in
 
high-stakes
 
legal
 
fields
 
(Chang
 
et
 
al.,
 
2024),
 
prioritizing
 
qualitative
 
judgment
 
across
 
five
 
critical
 
dimensions:
 
Benchmarking  Metrics  
1.  Jurisdictional  Precision  (The  "Conflict  of  Laws"  Test):  Migrant  workers  often  face  
conflicting
 
statutes
 
between
 
their
 
home
 
and
 
host
 
nations.
 
To
 
evaluate
 
this,
 
experts
 
will
 
assess
 
the
 
model's
 
performance
 
on
 
a
 
"Complex
 
Scenario"
 
dataset
 
where
 
Hong
 
Kong
 
and
 
Philippine
 
laws
 
diverge
 
(e.g.,
 
mandatory
 
Philippine
 
13th
 
Month
 
Pay
 
vs.
 
conditional
 
Hong
 
Kong
 
End
 
of
 
Year
 
Payment).
 
Consistent  with  Guha  et  al.  (2023),  who  established  that  generic  models  struggle  with  
jurisdictional
 
segregation,
 
we
 
hypothesize
 
the
 
baseline
 
will
 
frequently
 
misapply
 
Philippine
 
rights
 
Data  Validation  Record  
Query  RAG  Output  
Reasoning  Output  
Instruction  LLM  Response  
Expert  Scoring  (Interpretability  of  Legalese)  
Expert  Scoring  (Accuracy  of  Labor  Law  Citation)  
User  Inquiry  
Top_k  results  
CoT   Chatbot  Response  
Likert  Scale  1-5  Likert  Scale  1-5  

===== PAGE 15 =====
14  to  Hong  Kong  contracts.  In  contrast,  the  proposed  architecture  utilizes  a  Dual-Jurisdiction  Router  
to
 
enforce
 
strict
 
legal
 
context
 
segregation.
 
2.  Resistance  to  Hallucination  (Factual  Grounding):  Experts  will  review  responses  to  
simple
 
factual
 
queries
 
to
 
verify
 
that
 
cited
 
legal
 
articles
 
exist
 
within
 
official
 
government
 
corpora.
 
Since
 
human
 
evaluation
 
is
 
the
 
only
 
reliable
 
method
 
for
 
detecting
 
plausible
 
but
 
fictitious
 
citations
 
(Chang
 
et
 
al.,
 
2024),
 
any
 
response
 
citing
 
non-existent
 
statutes
 
will
 
be
 
penalized.
 
We
 
anticipate
 
the
 
proposed
 
model
 
will
 
outperform
 
the
 
baseline
 
by
 
utilizing
 
a
 
Graph-based
 
Verification
 
Layer
 
that
 
restricts
 
generation
 
exclusively
 
to
 
verified
 
government
 
documents.
 
3.  Temporal  Validity  (The  "Repealed  Law"  Trap):  To  prevent  the  citation  of  outdated  
regulations,
 
we
 
will
 
measure
 
the
 
Temporal
 
Rejection
 
Rate
 
using
 
a
 
dataset
 
of
 
"Temporal
 
Traps"
 
(e.g.,
 
pre-2024
 
wage
 
rates,
 
lifted
 
Covid-19
 
bans).
 
As
 
noted
 
in
 
Structure-Aware
 
Temporal
 
Graph
 
RAG
 
(2025),
 
standard
 
semantic
 
retrieval
 
often
 
retrieves
 
obsolete
 
documents
 
due
 
to
 
semantic
 
matching.
 
The
 
proposed
 
model
 
employs
 
a
 
metadata
 
filtering
 
layer
 
to
 
ensure
 
a
 
near-perfect
 
rejection
 
of
 
inactive
 
laws,
 
whereas
 
the
 
baseline
 
is
 
expected
 
to
 
hallucinate
 
active
 
status
 
for
 
repealed
 
policies.
 
4.  Distress  Detection  Safety  (SOS  Protocol):  Given  the  user  base's  vulnerability,  the  
system
 
must
 
reliably
 
identify
 
emergency
 
signals
 
(e.g.,
 
unlawful
 
detention).
 
We
 
will
 
measure
 
the
 
Distress
 
Detection
 
Rate
 
by
 
simulating
 
high-risk
 
scenarios;
 
failure
 
to
 
trigger
 
the
 
hard-coded
 
SOS
 
protocol
 
is
 
a
 
critical
 
error.
 
Following
 
the
 
safety
 
framework
 
of
 
Arnaiz-Rodriguez
 
et
 
al.
 
(2025),
 
which
 
argues
 
that
 
generative
 
models
 
are
 
unsafe
 
during
 
crises,
 
the
 
proposed
 
system
 
is
 
programmed
 
to
 
bypass
 
generative
 
AI
 
entirely
 
in
 
favor
 
of
 
rule-based
 
intervention
 
during
 
detected
 
emergencies.
 
5.  Economic  Sustainability  (Token  Cost  Efficiency):  To  ensure  viability  for  public  
sector
 
deployment,
 
we
 
will
 
assess
 
Token
 
Cost
 
Efficiency.
 
Citing
 
Chen
 
et
 
al.
 
(2023)
 
and
 
the
 
FrugalGPT
 
framework,
 
we
 
posit
 
that
 
intelligent
 
model
 
routing
 
significantly
 
reduces
 
costs.
 
By
 
employing
 
Adaptive
 
Literacy
 
Routing
 
to
 
simplify
 
answers
 
and
 
reduce
 
verbosity,
 
the
 
proposed
 
architecture
 
is
 
projected
 
to
 
achieve
 
a
 
lower
 
cost
 
per
 
query
 
compared
 
to
 
standard
 
models,
 
making
 
it
 
a
 
sustainable
 
long-term
 
government
 
solution.
 
Evaluation  Dimension  
Metric  Name  Method  of  Measurement  
Proposed  Goal  Evaluation  Dimension  
Correct  Country  Law  
Jurisdictional  Accuracy  
Expert  Panel  Review  (Pass/Fail)  
>90%  Accuracy  (Correctly  separates  HK  vs  PH  laws)  
Correct  Country  Law  

===== PAGE 16 =====
15  
Table  2:  Proposed  Comparative  Evaluation  Framework  and  Goals  
4.5.3  Evaluation  Criteria  for  the  Experts  
To  ensure  the  validation  dataset  meets  the  "Gold  Standard"  reliability  defined  by  Silveira  
et
 
al.
 
(2014)
 
and
 
ISO
 
24028:2020,
 
the
 
expert
 
panel
 
comprising
 
faculty
 
from
 
the
 
SLU
 
School
 
of
 
Law,
 
DMW
 
case
 
officers,
 
and
 
UPD
 
College
 
of
 
Law
 
faculty
 
will
 
evaluate
 
the
 
system
 
outputs
 
using
 
a
 
standardized
 
5-Point
 
Likert
 
Scale.
 
While
 
automated
 
metrics
 
assess
 
computational
 
efficiency,
 
this
 
expert-led
 
evaluation
 
focuses
 
strictly
 
on
 
the
 
qualitative
 
dimensions
 
of
 
legal
 
reliability
 
and
 
user
 
safety.
 
The  panel  will  grade  each  response  based  on  the  following  five  critical  dimensions:  
1.  Substantive  Legal  Correctness  (Factual  Grounding)  This  criterion  corresponds  to  the  
"Accuracy
 
of
 
Labor
 
Law
 
Citation"
 
column
 
in
 
Table
 
1.
 
Experts
 
assess
 
whether
 
the
 
system’s
 
advice
 
is
 
legally
 
sound
 
and
 
supported
 
by
 
valid
 
provisions
 
of
 
the
 
Hong
 
Kong
 
Employment
 
Ordinance.
 
1.  5  (Excellent):  The  response  cites  the  correct  ordinance  section,  accurately  interprets  the  
provision,
 
and
 
applies
 
it
 
correctly
 
to
 
the
 
user's
 
query
 
without
 
any
 
hallucination.
 2.  3  (Acceptable):  The  advice  is  generally  correct  but  lacks  specific  statutory  citations  or  
omits
 
minor
 
nuances.
 
Repealed  Law  Safety  
Temporal  Rejection  Rate  
Expert  Review  of  "Trap"  Queries  
Pass  (Identifies  repealed  laws  as  inactive)  
Repealed  Law  Safety  
Fact  Checking  Legal  Accuracy  Expert  Panel  Review  (Likert  Scale)  
>4.5/5  (Cites  real  laws  only)  
Fact  Checking  
User  Safety  Distress  Detection  Rate  
Simulation  Testing  
100%  (Never  misses  an  SOS  signal)  
User  Safety  
Sustainability  Cost  Efficiency  Tokens  per  Response  
Lower  Cost  (Shorter,  structured  answers)  
Sustainability  

===== PAGE 17 =====
16  3.  1  (Critical  Failure):  The  response  is  legally  incorrect,  cites  non-existent  laws  
(hallucination),
 
or
 
provides
 
advice
 
that
 
contradicts
 
the
 
statute.
 
2.  Jurisdictional  Precision  (The  "Conflict  of  Laws"  Test)  Experts  evaluate  the  model's  ability  
to
 
segregate
 
legal
 
contexts,
 
ensuring
 
it
 
does
 
not
 
conflate
 
Philippine
 
benefits
 
(e.g.,
 
13th
 
Month
 
Pay)
 
with
 
Hong
 
Kong
 
obligations.
 
1.  5  (Precise):  The  model  explicitly  identifies  Hong  Kong  Law  as  the  governing  framework  
and
 
correctly
 
rejects
 
the
 
application
 
of
 
home-country
 
laws
 
where
 
inappropriate.
 2.  3  (Ambiguous):  The  model  gives  correct  advice  but  fails  to  explicitly  state  which  
jurisdiction’s
 
law
 
is
 
being
 
applied.
 3.  1  (Misgrounded):  The  model  incorrectly  applies  Philippine  labor  laws  to  a  Hong  Kong  
employment
 
contract,
 
creating
 
a
 
"jurisdictional
 
hallucination."
 
3.  Linguistic  Accessibility  (Interpretability  of  Legalese)  This  criterion  corresponds  to  the  
"Interpretability
 
of
 
Legalese"
 
column
 
in
 
Table
 
1.
 
It
 
measures
 
the
 
system’s
 
ability
 
to
 
translate
 
complex
 
"Legalese"
 
into
 
accessible,
 
code-switched
 
(Taglish)
 
content
 
suitable
 
for
 
the
 
target
 
demographic.
 
1.  5  (High  Clarity):  The  response  is  empathetic,  uses  natural  Taglish,  and  simplifies  legal  
concepts
 
into
 
the
 
ALAC
 
format
 
(Answer,
 
Legal
 
Basis,
 
Advice,
 
Caveat)
 
without
 
losing
 
meaning.
 2.  3  (Standard):  The  response  is  accurate  but  uses  dense  vocabulary  or  retains  too  much  
formal
 
legal
 
jargon.
 3.  1  (Incomprehensible):  The  response  is  overly  verbose,  robotic,  or  uses  language  too  
complex
 
for
 
a
 
non-expert
 
user.
 
4.  Temporal  Validity  (Currency  of  Law)  Experts  verify  that  the  system  is  referencing  the  most  
current
 
regulations,
 
specifically
 
checking
 
for
 
the
 
"Temporal
 
Traps"
 
defined
 
in
 
the
 
dataset
 
(e.g.,
 
current
 
Minimum
 
Allowable
 
Wage
 
vs.
 
previous
 
years).
 
1.  5  (Current):  The  response  cites  the  regulation  effective  as  of  the  current  fiscal  year  and  
identifies
 
repealed
 
laws
 
as
 
inactive.
 2.  1  (Obsolete):  The  response  provides  advice  based  on  outdated  circulars,  repealed  
pandemics
 
restrictions,
 
or
 
old
 
wage
 
orders.
 
5.  Distress  Detection  and  Safety  (SOS  Compliance)  For  queries  involving  abuse,  unlawful  
detention,
 
or
 
trafficking,
 
experts
 
grade
 
the
 
system’s
 
adherence
 
to
 
the
 
hard-coded
 
safety
 
protocol.
 
1.  Pass  (Safe):  The  system  successfully  refuses  to  generate  a  standard  legal  answer  and  
triggers
 
the
 
SOS/Emergency
 
Referral
 
script.
 2.  Fail  (Unsafe):  The  system  attempts  to  provide  conversational  advice  or  legal  suggestions  
during
 
a
 
detected
 
crisis
 
scenario,
 
which
 
is
 
considered
 
a
 
critical
 
safety
 
violation.
 

===== PAGE 18 =====
17  4.5.3.1  Interpretability  Criteria  
For  the  evaluation  of  interpretability,  standard  AI  metrics  such  as  ROGUE  would  not  be  
sufficient
 
to
 
evaluate
 
the
 
readability,
 
despite
 
being
 
able
 
to
 
show
 
how
 
accurate
 
the
 
response
 
is,
 
for
 
they
 
have
 
been
 
proven
 
insufficient
 
to
 
capture
 
the
 
differences
 
in
 
every
 
legal
 
reasoning
 
(Mullick
 
et
 
al,
 
2022).
 
Thus,
 
conciseness,
 
clarity/readability,
 
and
 
comprehension
 
test
 
with
 
a
 
Likert
 
scale
 
of
 
one
 
to
 
5
 
is
 
introduced,
 
bringing
 
human-centric
 
evaluation.
 
Ranking
 
Factual
 
Accuracy
 
and
 
Legal
 
Accuracy
 
in
 
Likert
 
scale
 
is
 
created
 
to
 
underline
 
any
 
presence
 
of
 
Hallucination,
 
lest
 
developers
 
of
 
AI
 
want
 
to
 
promote
 
mistakes
 
as
 
providing
 
misleading
 
information
 
that
 
would
 
induce
 
civil
 
liability,
 
making
 
it
 
malpractice
 
(Munir,
 
2025).
 
Moreover,  the  classification  of  the  level  of  Error  Severity  wasn’t  often  equal,  where  a  typo  would  
be
 
minor
 
and
 
simply
 
annoying
 
to
 
watch,
 
citing
 
a
 
false
 
case
 
and
 
laws
 
and
 
regulations
 
would
 
jeopardize
 
credibility,
 
and
 
invoking
 
severe
 
error,
 
and
 
sometimes,
 
induce
 
legal
 
consequences
 
to
 
those
 
accepting
 
legal
 
advice
 
given
 
by
 
the
 
model.
 
Singh
 
(2025)
 
proposed
 
a
 
risk-weight
 
hallucination
 
scoring
 
specifically
 
for
 
the
 
legal
 
domain,
 
whereas
 
errors
 
were
 
categorized
 
as
 
“inefficiency”(minor)
 
versus
 
“malpractice”
 
(major).
 
The
 
evaluation
 
took
 
reference
 
from
 
it,
 
outlining
 
the
 
error
 
margins
 
evaluators
 
expected
 
in
 
each
 
of
 
those
 
categories,
 
namely
 
“minor”,”
 
moderate”,
 
and
 
“major”.
 
The
 
dataset
 
created
 
in
 
the
 
previous
 
steps
 
would
 
be
 
given
 
to
 
the
 
legal
 
experts
 
4.5.4  Pipeline  -  Adaptive  Framework  Design  
 Figure  4:  Adaptive  Router  Pipeline  Process   


===== PAGE 19 =====
18  
 
Figure  5:  Adaptive  Router  Technical  Process   
As  shown  in  Figure  4  (Adaptive  Router  Pipeline  Process)  and  a  technical  flow  in  Figure  5  
(Adaptive
 
Router
 
Technical
 
Process),
 
the
 
system
 
operates
 
through
 
a
 
modular
 
legal
 
AI
 
pipeline
 
designed
 
to
 
ensure
 
jurisdictional
 
accuracy,
 
expert
 
alignment,
 
and
 
safety
 
compliance.
 
User
 
queries
 
are
 
initially
 
processed
 
by
 
the
 
Triage
 
Module,
 
where
 
language
 
normalization,
 
intent
 
detection,
 
and
 
jurisdiction
 
classification
 
are
 
performed
 
as
 
part
 
of
 
the
 
adaptive
 
routing
 
layer
 
(Figure
 
4).
 
The
 
normalized
 
query
 
is
 
then
 
forwarded
 
to
 
the
 
Legal
 
Engine,
 
which
 
retrieves
 
the
 
relevant
 
statutes,
 
regulations,
 
and
 
jurisprudence
 
from
 
the
 
indexed
 
Labor
 
Law
 
Corpora
 
using
 
a
 
retrieval-augmented
 
generation
 
(RAG)
 
workflow
 
supported
 
by
 
vector
 
embeddings
 
and
 
similarity
 
search
 
(Figure
 
5).
 
Legal
 
reasoning
 
is
 
applied
 
to
 
synthesize
 
an
 
initial
 
response
 
grounded
 
in
 
authoritative
 
texts.
 
Next,
 
Expert
 
Routing
 
dynamically
 
selects
 
the
 
most
 
appropriate
 
expert-aligned
 
LLM
 
based
 
on
 
legal
 
domain,
 
jurisdiction,
 
and
 
risk
 
level.
 
Finally,
 
a
 
Safety
 
Audit
 
layer
 
conducts
 
post-generation
 
verification
 
using
 
JUDGE-BERT
 
to
 
assess
 
factual
 
consistency,
 
legal
 
correctness,
 
and
 
safety
 
before
 
the
 
response
 
is
 
released
 
to
 
the
 
user.
 
 
 


===== PAGE 20 =====
19  Annexes  A.  Plan  for  dissemination   To  bring  the  study  to  light,  the  study  is  planned  to  contribute  in  the  following  ways:  For  the  discussion  of  Multi-Model  Routing  among  researchers,  this  study  could  be  published  in  
the
 
International
 
Conference
 
on
 
Humanoid,
 
Nanotechnology,
 
Information
 
Technology,
 
Communication
 
and
 
Control,
 
Environment,
 
and
 
Management.
 
(HNICEM)
 
On
 
the
 
other
 
hand,
 
to
 
put
 
our
 
experience
 
into
 
good
 
use,
 
the
 
project
 
can
 
be
 
deployed
 
in
 
collaboration
 
with
 
DMW
 
and
 
DICT,
 
should
 
there
 
be
 
any
 
need
 
for
 
edition
 
and
 
augmentation
 
before
 
integrating
 
into
 
the
 
government
 
website.
 
B.  Work  plan  and  schedule  of  activities  (Gantt  chart)  
 Figure  6:  Methodology  &  Implementation  Gantt  Chart    
 
 
   


===== PAGE 21 =====
20  C.  Expert-Academic  Partnerships  
  Figure  7:  Snapshots  of  Collaboration  Acceptance  from  UPD  (College  of  Law)  and  
DMW-CAR
 
(
 
Department
 
of
 
Migrant
 
Workers)
  
  Figure  8:  Snapshot  of  the  Confirmation  of  Faculty  Assistance  From  Saint  Louis  
University
 
School
 
of
 
Law
 


===== PAGE 22 =====
21    References  
Agada,  J.  O.,  Folashade,  A.  G.,  Biswas,  A.,  &  other  authors.  (2025).  A  systematic  review  
of
 
key
 
retrieval-augmented
 
generation
 
(RAG)
 
systems:
 
Progress,
 
gaps,
 
and
 
future
 
directions.
  https://arxiv.org/abs/2507.18910 
Aguilar  ,G.,  Kar,  S.,  and  Solorio,  T.,  2020.  LinCE:  A  Centralized  Benchmark  for  
Linguistic
 
Code-switching
 
Evaluation.
 
In
 
Proceedings
 
of
 
the
 
Twelfth
 
Language
 
Resources
 
and
 
Evaluation
 
Conference,
 
pages
 
1803–1813,
 
Marseille,
 
France.
 
European
 
Language
 
Resources
 
Association.
 
Alva-Manchego,  F.,  Martin,  L.,  Bordes,  A.,  Scarton,  C.,  Sagot,  B.,  &  Specia,  L.  (2020).  
ASSET:
 
A
 
dataset
 
for
 
tuning
 
and
 
evaluation
 
of
 
sentence
 
simplification
 
models.
 
In
 
Proceedings
 
of
 
the
 
58th
 
Annual
 
Meeting
 
of
 
the
 
Association
 
for
 
Computational
 
Linguistics
 
(pp.
 
4665–4675).
 Association  for  Computational  Linguistics.  https://aclanthology.org/2020.acl-main.424/ 
Amerishi,  S.,  Weld,  D.,  Vorvoreanu,  M.,  Fournier,  A.,  Nushi,  B.,  Collisson,  P.,  ...  Horvitz,  
E.
 
(2019).
 
Guidelines
 
for
 
human-AI
 
interaction.
 
In
 
Proceedings
 
of
 
the
 
2019
 
CHI
 
Conference
 
on
 
Human
 
Factors
 
in
 
Computing
 
Systems
 
(pp.
 
1–13).
 
Association
 
for
 
Computing
 
Machinery.
 https://doi.org/10.1145/3290605.3300233 
Battistella,  G.,  &  Asis,  M.  M.  B.  (2011).  Protecting  Filipino  transnational  domestic  
workers:
 
Government
 
regulations
 
and
 
their
 
outcomes
 
(Discussion
 
Paper
 
Series
 
No.
 
2011-12).
 
Philippine
 
Institute
 
for
 
Development
 
Studies.
 https://www.pids.gov.ph/publication/discussion-papers/protecting-filipino-transnational-domestic-workers-government-regulations-and-their-outcomes 
Cabalquinto,  E.  C.,  &  Soriano,  C.  R.  (2022).  Performing  "digital  labor  bayanihan":  
Strategies
 
of
 
influence
 
and
 
survival
 
in
 
the
 
platform
 
economy.
 
Symposium
 
on
 
Platform
 
Labor,
 
Monash
 
University.
 https://research.monash.edu/en/publications/performing-digital-labor-bayanihan-strategies-of-influence-and-survival 
Choy,  C.  Y.,  Chang,  L.,  &  Man,  P.  Y.  (2022).  Social  support  and  coping  among  female  
foreign
 
domestic
 
helpers
 
experiencing
 
abuse
 
and
 
exploitation
 
in
 
Hong
 
Kong.
 
Frontiers
 
in
 Communication,  7,  1015193.  https://doi.org/10.3389/fcomm.2022.1015193 
Chua,  X.,  Tan,  D.,  Oi,  J.  J.,  &  Tan,  J.  (2023,  September  30).  Project  MigrantPal:  
Harnessing
 
digital
 
technology
 
to
 
improve
 
the
 
well-being
 
of
 
migrant
 
workers
 
in
 
Singapore,
 
the
 
Reach
 
Alliance.
 
The
 
Reach
 
Alliance.
 https://reachalliance.org/case-study/harnessing-digital-technology-to-improve-the-well-being-of-migrant-workers-in-singapore/ 

===== PAGE 23 =====
22  Claude-3  Model  Card  Anthropic.  (2024).  The  Claude  3  model  family:  Opus,  Sonnet,  
Haiku
 
[Model
 
card].
 
Anthropic.
 https://assets.anthropic.com/m/61e7d27f8c8f5919/original/Claude-3-Model-Card.pdf 
Dahl,  M.,  Magesh,  V.,  Suzgun,  M.,  &  Ho,  D.  E.  (2024).  Large  Legal  Fictions:  Profiling  
legal
 
hallucinations
 
in
 
large
 
language
 
models.
 
The
 
Journal
 
of
 
Legal
 
Analysis,
 
16(1),
 
64–93.
 https://doi.org/10.1093/jla/laae003 
European  Journal  of  Computer  Science  and  Information  Technology.  (2025).  The  
evolving
 
role
 
of
 
human-in-the-loop
 
evaluations
 
in
 
advanced
 
AI
 
systems.
 
EA
 
Journals.
 https://ejcsit.org/ejcsit/ 
Gao,  L.,  Tang,  R.,  &  Lin,  J.  (2024).  A  comprehensive  survey  of  retrieval-augmented  
generation
 
(RAG)
 
evaluation
 
and
 
benchmarks.
 
ResearchGate.
 
Gemini  2.5  Pro  Model  Card  Google.  (n.d.).  *Gemini  2.5  Pro  model  card.  Google  Model  Cards.  https://modelcards.withgoogle.com/assets/documents/gemini-2.5-pro.pdf 
GPT-4  Technical  Report  OpenAI.  (2023).  GPT-4  technical  report.  OpenAI.  https://cdn.openai.com/papers/gpt-4.pdf 
Guinto,  N.  L.  (2021).  Communicative  repertoires,  place-making,  and  transnational  
domestic
 
labor:
 
Filipino
 
domestic
 
workers
 
in
 
Hong
 
Kong
 
(Doctoral
 
thesis).
 
The
 
University
 
of
 Hong  Kong.  https://hub.hku.hk/handle/10722/300421 
Han,  J.,  Kim,  S.,  &  Park,  J.  (2025).  Temporal  GraphRAG:  Modeling  evolving  knowledge  for  time-aware  retrieval-augmented  generation.  https://arxiv.org/abs/2510.13590 
Hong  Kong  Government.  (2023).  Hong  Kong  Yearbook  2023:  Labour  (E14).  Retrieved  from  https://www.yearbook.gov.hk/2023/en/pdf/E14.pdf 
Hong  Kong  Philippine  Consulate  General.  (2025).  Owwa-dmw  Serbisyo  Caravan  
Successfully
 
Delivers
 
One-stop
 
Services
 
To
 
OFWs
 
In
 
Hong
 
Kong.
 https://hongkongpcg.dfa.gov.ph/site-administrator/embassy-news/1822-owwa-dmw-serbisyo-caravan-successfully-delivers-one-stop-services-to-ofws-in-hong-kong 
Ibrahim,  H.,  Huang,  S.,  Ahmad,  M.,  &  Anderljung,  M.  (2024).  Evaluating  real-world  
risks
 
of
 
large
 
language
 
models
 
through
 
human-centered
 
assessments.
 https://arxiv.org/abs/2405.10632 
International  Labour  Organization.  (2017).  Migrant  workers  in  South-East  Asia  lack  access  to  fair,  responsive  legal  remedies.  UN  News.  https://news.un.org/en/story/2017/07/562352 
Java,  A.,  Patel,  V.,  &  Roy,  S.  (2025).  FrugalRAG:  Iterative  sub-query  decomposition  for  
efficient
 
multi-hop
 
retrieval.
 

===== PAGE 24 =====
23  Jeong,  et  al.  (2024).  Adaptive  retrieval  strategies  based  on  query  complexity  enhance  
efficiency
 
and
 
accuracy
 
in
 
RAG
 
systems.
 
Emergent
 
Mind.
 https://www.emergentmind.com/topics/adaptive-retrieval-augmented-generation-adaptive-rag 
Kalra,  R.,  Wu,  Z.,  Gulley,  A.,  Hilliard,  A.,  Guan,  X.,  Koshiyama,  A.,  &  Treleaven,  P.  C.  
(2024).
 
HyPA-RAG:
 
A
 
hybrid
 
parameter-adaptive
 
retrieval-augmented
 
generation
 
system
 
for
 
AI
 legal  and  policy  applications.  ACL  Anthology.  https://aclanthology.org/2024.customlm4-u.118/ 
Koreeda,  Y.,  &  Manning,  C.  D.  (2021).  ContractNLI:  A  dataset  for  document-level  
natural
 
language
 
inference
 
for
 
contracts.
 
In
 
M.-F.
 
Moens,
 
X.
 
Huang,
 
L.
 
Specia
 
&
 
S.
 
W.-T.
 
Yih
 
(Eds.),
 
Findings
 
of
 
the
 
Association
 
for
 
Computational
 
Linguistics:
 
EMNLP
 
2021
 
(pp.
 
1907–1919).
 
Association
 
for
 
Computational
 
Linguistics.
 https://doi.org/10.18653/v1/2021.findings-emnlp.164 
Lee,  S.,  Kwon,  T.,  &  Jin,  D.  (2025).  GRADE:  Generating  multi-hop  QA  datasets  with  fine-grained  difficulty  modeling.  https://arxiv.org/abs/2508.16994 
Lepri,  B.,  Oliver,  N.,  &  Pentland,  A.  (2021).  Ethical  machines:  The  human-centric  use  of  artificial  intelligence.  iScience,  24(3),  102249.  https://doi.org/10.1016/j.isci.2021.102249 
Lewis,  P.,  et  al.  (2020).  Retrieval-Augmented  Generation  for  knowledge-intensive  tasks:  
Combining
 
retrieval
 
with
 
generation
 
to
 
improve
 
performance
 
and
 
factual
 
grounding.
 
In
 
Proceedings
 
of
 
the
 
EMNLP
 
/
 
Business
 
&
 
Information
 
Systems
 
Engineering
 
(Springer).
 
Springer.
 
https://link.springer.com/article/10.1007/s12599-025-00945-3
 
(Original
 
RAG
 
concept
 
and
 
framework
 
discussion)
 
Lewis,  P.,  Izacard,  G.,  Lachaux,  M.,  &  Riedel,  S.  (2020).  Retrieval-augmented  generation  
for
 
knowledge-intensive
 
NLP
 
tasks.
 
Advances
 
in
 
Neural
 
Information
 
Processing
 
Systems,
 
33,
 
9459–9474.
 
Lim,  W.,  &  Visaria,  S.  (2020).  The  borrowing  puzzle:  Why  do  Filipino  domestic  workers  
in
 
Hong
 
Kong,
 
China,
 
borrow
 
rather
 
than
 
dissolve?
 
Asian
 
Development
 
Review,
 
37(2),
 
77–99.
 https://doi.org/10.1162/adev_a_00150 
Mak,  A.  (2025,  October  5).  Why  are  Domestic  Helpers  so  Common  in  Hong  Kong?  Veritas.  https://veritasnewspaper.com/post/why-are-domestic-helpers-so-common-in-hong-kong 
Martinez,  E.,  Mollica,  F.,  &  Gibson,  E.  (2023).  Even  lawyers  don’t  like  legalese.  
Proceedings
 
of
 
the
 
National
 
Academy
 
of
 
Sciences,
 
120(24),
 
e2301686120.
 https://www.pnas.org/doi/10.1073/pnas.2302672120 
Mullick,  A.,   Abhilash  Nandy,  Manav  Kapadnis,  Sohan  Patnaik,  Raghav  R,  and  Roshni  
Kar.
 
2022.
 
An
 
Evaluation
 
Framework
 
for
 
Legal
 
Document
 
Summarization.
 
In
 
Proceedings
 
of
 
the
 
Thirteenth
 
Language
 
Resources
 
and
 
Evaluation
 
Conference,
 
pages
 
4747–4753,
 
Marseille,
 
France.
 
European
 
Language
 
Resources
 
Association.
 

===== PAGE 25 =====
24  Munir,  Bakht,  Hallucinations  in  Legal  Practice:  A  Comparative  Case  Law  Analysis  
(February
 
24,
 
2025).
 
International
 
Journal
 
of
 
Law,
 
Ethics,
 
and
 
Technology,
 
Available
 
at
 
SSRN:
 https://ssrn.com/abstract=5265375  or  http://dx.doi.org/10.2139/ssrn.5265375 
Muñoz,  A.  V.,  &  Muñoz,  M.  A.  V.  (2024).  AI  as  the  Invisible  Hand:  Redefining  OFW  
Welfare,
 
Family
 
Connectivity,
 
and
 
National
 
Development
 
in
 
the
 
Digital
 
Age.
 https://www.researchgate.net/publication/394792370_AI_as_the_Invisible_Hand_Redefining_OFW_Welfare_Family_Connectivity_and_National_Development_in_the_Digital_Age_by_AV_Munoz_and_MAV_Munoz 
Myllyaho,  R.,  Raatikainen,  M.,  Männistö,  T.,  Pöyhönen,  T.,  &  Mikkonen,  T.  (2021).  A  
systematic
 
review
 
of
 
human-in-the-loop
 
approaches
 
in
 
AI
 
system
 
validation.
 https://arxiv.org/abs/2107.12190 
Nguyen,  H.  T.,  &  Satoh,  K.  (2024).  KRAG  framework  for  enhancing  LLMs  in  the  legal  domain.  https://arxiv.org/abs/2410.07551 
Oktavianus,  J.  (2025).  Words  apart:  Unravelling  the  language  barrier  plight  of  migrant  
domestic
 
workers
 
in
 
Hong
 
Kong.
 
Language
 
and
 
Intercultural
 
Communication,
 
25(3),
 
349–364.
 https://doi.org/10.1080/14708477.2025.2520971 
Pipitone,  N.,  &  Alami,  G.  H.  (2024).  LegalBench-RAG:  Legal  retrieval  benchmark  for  retrieval-augmented  generation  in  the  legal  domain  (preprint).  https://arxiv.org/abs/2408.10343 
Reuter,  M.,  Lingenberg,  T.,  Liepina,  R.,  Lagioia,  F.,  Lippi,  M.,  Sartor,  G.,  Passerini,  A.,  &  
Sayin,
 
B.
 
(2025).
 
Towards
 
reliable
 
retrieval
 
in
 
RAG
 
systems
 
for
 
large
 
legal
 
datasets.
 
In
 
Proceedings
 
of
 
the
 
Natural
 
Language
 
Processing
 
Workshop
 
2025
 
(pp.
 
17–30).
 
Association
 
for
 Computational  Linguistics.  https://doi.org/10.18653/v1/2025.nlp-1.3 
Rojas,  E.  D.,  &  Narsico,  P.  G.  (2025).  "Digital  vs.  Traditional  Remittance  Preferences  
among
 
Overseas
 
Filipino
 
Workers:
 
Patterns,
 
Barriers,
 
and
 
Behavioral
 
Drivers."
 
International
 
Journal
 
of
 
Multidisciplinary
 
Applied
 
Business
 
and
 
Education
 
Research.
 
Ruiz,  N.  (2014).  Made  for  export:  labor  migration,  state  power,  and  higher  education  in  a  
developing
 
Philippine
 
economy.
 
MIT
 
Libraries.
 https://dspace.mit.edu/handle/1721.1/92054#...=text=President%20Ferdinand%20Marcos%20and%20his,received%20from%20Filipinos%20working%20abroad 
Schriver,  K.  A.  (2017).  Plain  language  in  the  United  States  gained  momentum:  
1940–2015.
 
IEEE
 
Transactions
 
on
 
Professional
 
Communication,
 
60(4),
 
343–383.
 https://doi.org/10.1109/TPC.2017.2765918 
Sicat,  A.  T.  (2020)  Overseas  Filipino  workers  (OFWs)  in  Hong  Kong:  Demographic  
correlates
 
and
 
insights
 
on
 
their
 
state
 
of
 
well-being.
 
Ad
 
Meliora,
 
2(1).
 https://rpo.ua.edu.ph/wp-content/uploads/2023/10/1.-Ad-Meliora-2019-2020-OFWs-in-Hong-Kong-1.pdf 

===== PAGE 26 =====
25  Silveira,  N.,  Dozat,  T.,  de  Marneffe,  M.-C.,  Bowman,  S.,  &  Manning,  C.  D.  (2014).  A  
gold
 
standard
 
dependency
 
corpus
 
for
 
English.
 
Proceedings
 
of
 
the
 
Ninth
 
International
 
Conference
 
on
 
Language
 
Resources
 
and
 
Evaluation
 
(LREC
 
2014),
 
Reykjavik,
 
Iceland.
 https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=920f120562fef3df07c8e8f7c61c8a8c8e8797d1 
Singh,  S.  K.,  Risk-weighted  hallucination  scoring  for  legal  answers:  A  conceptual  
framework
 
for
 
trustworthy
 
AI
 
in
 
law.
 
International
 
Journal
 
of
 
Innovative
 
Science
 
and
 
Research
 Technology,  10(1).  https://doi.org/10.38124/ijisrt/25nov1315 
TIMETOACT  GROUP  LLM  Benchmarks  TIMETOACT  GROUP.  (2024,  November).  
LLM
 
performance
 
benchmarks
 
–
 
November
 
2024
 
update.
 
TIMETOACT
 
GROUP.
 https://www.timetoact-group.at/en/insights/llm-benchmarks/llm-benchmarks-november-2-024 
Tumbull,  M.,  Ching,  T.,  &  Yu,  C.  (2023).  Perceptions  of  health  and  coping  strategies  
among
 
temporary
 
migrant
 
workers
 
in
 
East
 
and
 
Southeast
 
Asia:
 
A
 
systematic
 
review.
 International  Journal  for  Equity  in  Health,  22,  32.  https://doi.org/10.1186/s12939-023-01840-7 
Wei,  J.,  Wang,  X.,  Schuurmans,  D.,  et  al.  (2022).  Chain-of-thought  prompting  elicits  
reasoning
 
in
 
large
 
language
 
models.
 
Advances
 
in
 
Neural
 
Information
 
Processing
 
Systems,
 
35,
 
24824–24837.
 https://proceedings.neurips.cc/paper_files/paper/2022/file/9d5ed678fe57bcca4e708f84a6a48a096-Paper-Conference.pdf 
Williams,  S.,  et  al.  (2023).  "LegalBench:  A  Collaboratively  Built  Benchmark  for  
Measuring
 
Legal
 
Reasoning
 
in
 
Large
 
Language
 
Models."
 https://proceedings.neurips.cc/paper_files/paper/2023/hash/89e44582fd28ddfea1ea4dcb0ebbf4b0-Abstract-Datasets_and_Benchmarks.html 
Yao,  R.,  Wu,  Y.,  Wang,  C.,  Xiong,  J.,  Wang,  F.,  &  Liu,  X.  (2025).  Elevating  legal  LLM  
responses:
 
Harnessing
 
trainable
 
logical
 
structures
 
and
 
semantic
 
knowledge
 
with
 
legal
 
reasoning.
 
In
 
Proceedings
 
of
 
the
 
2025
 
Conference
 
of
 
the
 
North
 
American
 
Chapter
 
of
 
the
 
Association
 
for
 
Computational
 
Linguistics:
 
Human
 
Language
 
Technologies
 
(Long
 
Papers)
 
(pp.
 
5630–5642).
 
Association
 
for
 
Computational
 
Linguistics.
 
https://aclanthology.org/2025.naacl-long.290/
 
Ye,  F.,  Li,  S.,  Zhang,  Y.,  &  Chen,  L.  (2024).  RAG:  Incorporating  retrieval  information  
into
 
retrieval
 
augmented
 
generation.
 
In
 
Findings
 
of
 
the
 
Association
 
for
 
Computational
 
Linguistics:
 
EMNLP
 
2024
 
(pp.
 
11584–11596).
 
Association
 
for
 
Computational
 
Linguistics.
 https://aclanthology.org/2024.findings-emnlp.678/ 
Yeung,  J.  (2020).  Imagine  being  forced  to  live  with  your  boss.  That’s  the  case  for  nearly  
400,000
 
women
 
in
 
Hong
 
Kong.
 
CNN
 
World.
 https://edition.cnn.com/2020/07/09/asia/hong-kong-helper-live-in-rule-intl-hnk 
Zhang,  K.,  Yu,  W.,  Sun,  Z.,  &  Xu,  J.  (2025).  SyLeR:  A  framework  for  explicit  syllogistic  legal  reasoning  in  large  language  models.  https://arxiv.org/abs/2504.04042 

===== PAGE 27 =====
26  Zhang,  Y.  (2025).  A  retrieval-augmented  generation  framework  with  retriever  and  
generator
 
modules
 
for
 
enhancing
 
factual
 
consistency.
 
Applied
 
and
 
Computational
 
Engineering,
 166,  102–108.  https://direct.ewa.pub/proceedings/ace/article/view/24496 
Zhu,  W.,  Yu,  J.,  Zhang,  S.,  &  Chen,  Z.  (2022).  ReasonChainQA:  A  question  answering  a  
dataset
 
with
 
explicit
 
reasoning
 
chains.
 
https://arxiv.org/abs/2210.08763
 
 
 
 
 